{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b2ee1af-22c1-4182-9fce-52ecb2b1bc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a5ac117-283a-4731-a67f-acb76c4ee4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f523c402-23fb-4684-bf6e-709591b59880",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 9912422/9912422 [00:00<00:00, 11538600.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\train-images-idx3-ubyte.gz to data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 28881/28881 [00:00<00:00, 28889981.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 1648877/1648877 [00:00<00:00, 8747527.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4542/4542 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to data\\MNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# MNIST Dataset\n",
    "train_data = torchvision.datasets.MNIST(\n",
    "    root='data',\n",
    "    train=True,\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    "    download=True\n",
    ")\n",
    "\n",
    "test_data = torchvision.datasets.MNIST(\n",
    "    root='data',\n",
    "    train=False,\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    "    download=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6192077-2c40-425b-9f5f-106198148696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train data: torch.Size([60000, 28, 28])\n",
      "Shape of test data: torch.Size([10000, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(f'Shape of train data: {train_data.data.shape}')\n",
    "print(f'Shape of test data: {test_data.data.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28a5a173-e267-4bf6-ae96-49852ded7d6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 4,  ..., 5, 6, 8])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47681505-6f6e-4ac3-9966-77397b2d0ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_data,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "80831c0f-c38d-4743-b40b-ea748510cbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dc706c73-074c-4ab0-abc8-549ac2547594",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2c2c1dd2-d42e-413a-97bd-59a8a3cb5c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4ac00f85-77e9-42ef-8a6e-419e8526d27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_dataloader):\n",
    "        data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = loss_fn(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % 20 == 0:\n",
    "            print(f'Train epoch: {epoch}, [{batch_idx*len(data)}/{len(train_dataloader.dataset)}, ({100*batch_idx/len(train_dataloader):.3f}%)], loss: {loss.item():.6f}')\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(test_dataloader):\n",
    "            data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "            output = model(data)\n",
    "            test_loss += loss_fn(output, target).item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_dataloader.dataset)\n",
    "    print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_dataloader.dataset)} ({correct/(len(test_dataloader.dataset)):.3f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "866830c5-f6ab-4386-9eda-e68bdc1ff8fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dong\\AppData\\Local\\Temp\\ipykernel_6540\\1616078874.py:17: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch: 1, [0/60000, (0.000%)], loss: 0.295317\n",
      "Train epoch: 1, [1280/60000, (2.132%)], loss: 0.284774\n",
      "Train epoch: 1, [2560/60000, (4.264%)], loss: 0.342401\n",
      "Train epoch: 1, [3840/60000, (6.397%)], loss: 0.350270\n",
      "Train epoch: 1, [5120/60000, (8.529%)], loss: 0.580023\n",
      "Train epoch: 1, [6400/60000, (10.661%)], loss: 0.398987\n",
      "Train epoch: 1, [7680/60000, (12.793%)], loss: 0.207298\n",
      "Train epoch: 1, [8960/60000, (14.925%)], loss: 0.397964\n",
      "Train epoch: 1, [10240/60000, (17.058%)], loss: 0.286570\n",
      "Train epoch: 1, [11520/60000, (19.190%)], loss: 0.175699\n",
      "Train epoch: 1, [12800/60000, (21.322%)], loss: 0.340903\n",
      "Train epoch: 1, [14080/60000, (23.454%)], loss: 0.178692\n",
      "Train epoch: 1, [15360/60000, (25.586%)], loss: 0.298882\n",
      "Train epoch: 1, [16640/60000, (27.719%)], loss: 0.290195\n",
      "Train epoch: 1, [17920/60000, (29.851%)], loss: 0.274759\n",
      "Train epoch: 1, [19200/60000, (31.983%)], loss: 0.307639\n",
      "Train epoch: 1, [20480/60000, (34.115%)], loss: 0.220385\n",
      "Train epoch: 1, [21760/60000, (36.247%)], loss: 0.247643\n",
      "Train epoch: 1, [23040/60000, (38.380%)], loss: 0.222603\n",
      "Train epoch: 1, [24320/60000, (40.512%)], loss: 0.150523\n",
      "Train epoch: 1, [25600/60000, (42.644%)], loss: 0.256284\n",
      "Train epoch: 1, [26880/60000, (44.776%)], loss: 0.280038\n",
      "Train epoch: 1, [28160/60000, (46.908%)], loss: 0.259994\n",
      "Train epoch: 1, [29440/60000, (49.041%)], loss: 0.147035\n",
      "Train epoch: 1, [30720/60000, (51.173%)], loss: 0.242927\n",
      "Train epoch: 1, [32000/60000, (53.305%)], loss: 0.210803\n",
      "Train epoch: 1, [33280/60000, (55.437%)], loss: 0.136768\n",
      "Train epoch: 1, [34560/60000, (57.569%)], loss: 0.371752\n",
      "Train epoch: 1, [35840/60000, (59.701%)], loss: 0.161309\n",
      "Train epoch: 1, [37120/60000, (61.834%)], loss: 0.228134\n",
      "Train epoch: 1, [38400/60000, (63.966%)], loss: 0.244729\n",
      "Train epoch: 1, [39680/60000, (66.098%)], loss: 0.302205\n",
      "Train epoch: 1, [40960/60000, (68.230%)], loss: 0.209416\n",
      "Train epoch: 1, [42240/60000, (70.362%)], loss: 0.282411\n",
      "Train epoch: 1, [43520/60000, (72.495%)], loss: 0.331463\n",
      "Train epoch: 1, [44800/60000, (74.627%)], loss: 0.279155\n",
      "Train epoch: 1, [46080/60000, (76.759%)], loss: 0.145805\n",
      "Train epoch: 1, [47360/60000, (78.891%)], loss: 0.202370\n",
      "Train epoch: 1, [48640/60000, (81.023%)], loss: 0.231473\n",
      "Train epoch: 1, [49920/60000, (83.156%)], loss: 0.218700\n",
      "Train epoch: 1, [51200/60000, (85.288%)], loss: 0.355632\n",
      "Train epoch: 1, [52480/60000, (87.420%)], loss: 0.066121\n",
      "Train epoch: 1, [53760/60000, (89.552%)], loss: 0.091129\n",
      "Train epoch: 1, [55040/60000, (91.684%)], loss: 0.254224\n",
      "Train epoch: 1, [56320/60000, (93.817%)], loss: 0.216512\n",
      "Train epoch: 1, [57600/60000, (95.949%)], loss: 0.149634\n",
      "Train epoch: 1, [58880/60000, (98.081%)], loss: 0.126943\n",
      "\n",
      "Test set: Average loss: 0.0012, Accuracy: 9747/10000 (0.975%)\n",
      "Train epoch: 2, [0/60000, (0.000%)], loss: 0.156040\n",
      "Train epoch: 2, [1280/60000, (2.132%)], loss: 0.205516\n",
      "Train epoch: 2, [2560/60000, (4.264%)], loss: 0.108906\n",
      "Train epoch: 2, [3840/60000, (6.397%)], loss: 0.408143\n",
      "Train epoch: 2, [5120/60000, (8.529%)], loss: 0.323276\n",
      "Train epoch: 2, [6400/60000, (10.661%)], loss: 0.239672\n",
      "Train epoch: 2, [7680/60000, (12.793%)], loss: 0.243238\n",
      "Train epoch: 2, [8960/60000, (14.925%)], loss: 0.272656\n",
      "Train epoch: 2, [10240/60000, (17.058%)], loss: 0.273860\n",
      "Train epoch: 2, [11520/60000, (19.190%)], loss: 0.139845\n",
      "Train epoch: 2, [12800/60000, (21.322%)], loss: 0.217523\n",
      "Train epoch: 2, [14080/60000, (23.454%)], loss: 0.203012\n",
      "Train epoch: 2, [15360/60000, (25.586%)], loss: 0.350944\n",
      "Train epoch: 2, [16640/60000, (27.719%)], loss: 0.236752\n",
      "Train epoch: 2, [17920/60000, (29.851%)], loss: 0.154906\n",
      "Train epoch: 2, [19200/60000, (31.983%)], loss: 0.143873\n",
      "Train epoch: 2, [20480/60000, (34.115%)], loss: 0.212190\n",
      "Train epoch: 2, [21760/60000, (36.247%)], loss: 0.254506\n",
      "Train epoch: 2, [23040/60000, (38.380%)], loss: 0.353968\n",
      "Train epoch: 2, [24320/60000, (40.512%)], loss: 0.141616\n",
      "Train epoch: 2, [25600/60000, (42.644%)], loss: 0.159431\n",
      "Train epoch: 2, [26880/60000, (44.776%)], loss: 0.273859\n",
      "Train epoch: 2, [28160/60000, (46.908%)], loss: 0.289307\n",
      "Train epoch: 2, [29440/60000, (49.041%)], loss: 0.250415\n",
      "Train epoch: 2, [30720/60000, (51.173%)], loss: 0.132758\n",
      "Train epoch: 2, [32000/60000, (53.305%)], loss: 0.400841\n",
      "Train epoch: 2, [33280/60000, (55.437%)], loss: 0.351231\n",
      "Train epoch: 2, [34560/60000, (57.569%)], loss: 0.303121\n",
      "Train epoch: 2, [35840/60000, (59.701%)], loss: 0.129746\n",
      "Train epoch: 2, [37120/60000, (61.834%)], loss: 0.166142\n",
      "Train epoch: 2, [38400/60000, (63.966%)], loss: 0.198306\n",
      "Train epoch: 2, [39680/60000, (66.098%)], loss: 0.198811\n",
      "Train epoch: 2, [40960/60000, (68.230%)], loss: 0.323382\n",
      "Train epoch: 2, [42240/60000, (70.362%)], loss: 0.195517\n",
      "Train epoch: 2, [43520/60000, (72.495%)], loss: 0.219303\n",
      "Train epoch: 2, [44800/60000, (74.627%)], loss: 0.087861\n",
      "Train epoch: 2, [46080/60000, (76.759%)], loss: 0.321794\n",
      "Train epoch: 2, [47360/60000, (78.891%)], loss: 0.120949\n",
      "Train epoch: 2, [48640/60000, (81.023%)], loss: 0.405800\n",
      "Train epoch: 2, [49920/60000, (83.156%)], loss: 0.161946\n",
      "Train epoch: 2, [51200/60000, (85.288%)], loss: 0.226484\n",
      "Train epoch: 2, [52480/60000, (87.420%)], loss: 0.283455\n",
      "Train epoch: 2, [53760/60000, (89.552%)], loss: 0.203221\n",
      "Train epoch: 2, [55040/60000, (91.684%)], loss: 0.060909\n",
      "Train epoch: 2, [56320/60000, (93.817%)], loss: 0.370093\n",
      "Train epoch: 2, [57600/60000, (95.949%)], loss: 0.120689\n",
      "Train epoch: 2, [58880/60000, (98.081%)], loss: 0.138599\n",
      "\n",
      "Test set: Average loss: 0.0010, Accuracy: 9796/10000 (0.980%)\n",
      "Train epoch: 3, [0/60000, (0.000%)], loss: 0.227295\n",
      "Train epoch: 3, [1280/60000, (2.132%)], loss: 0.293893\n",
      "Train epoch: 3, [2560/60000, (4.264%)], loss: 0.105428\n",
      "Train epoch: 3, [3840/60000, (6.397%)], loss: 0.177822\n",
      "Train epoch: 3, [5120/60000, (8.529%)], loss: 0.038958\n",
      "Train epoch: 3, [6400/60000, (10.661%)], loss: 0.129359\n",
      "Train epoch: 3, [7680/60000, (12.793%)], loss: 0.212931\n",
      "Train epoch: 3, [8960/60000, (14.925%)], loss: 0.145227\n",
      "Train epoch: 3, [10240/60000, (17.058%)], loss: 0.101189\n",
      "Train epoch: 3, [11520/60000, (19.190%)], loss: 0.186144\n",
      "Train epoch: 3, [12800/60000, (21.322%)], loss: 0.176561\n",
      "Train epoch: 3, [14080/60000, (23.454%)], loss: 0.032174\n",
      "Train epoch: 3, [15360/60000, (25.586%)], loss: 0.095608\n",
      "Train epoch: 3, [16640/60000, (27.719%)], loss: 0.095704\n",
      "Train epoch: 3, [17920/60000, (29.851%)], loss: 0.100613\n",
      "Train epoch: 3, [19200/60000, (31.983%)], loss: 0.268066\n",
      "Train epoch: 3, [20480/60000, (34.115%)], loss: 0.140590\n",
      "Train epoch: 3, [21760/60000, (36.247%)], loss: 0.083673\n",
      "Train epoch: 3, [23040/60000, (38.380%)], loss: 0.133199\n",
      "Train epoch: 3, [24320/60000, (40.512%)], loss: 0.172568\n",
      "Train epoch: 3, [25600/60000, (42.644%)], loss: 0.165804\n",
      "Train epoch: 3, [26880/60000, (44.776%)], loss: 0.164146\n",
      "Train epoch: 3, [28160/60000, (46.908%)], loss: 0.092476\n",
      "Train epoch: 3, [29440/60000, (49.041%)], loss: 0.247784\n",
      "Train epoch: 3, [30720/60000, (51.173%)], loss: 0.191463\n",
      "Train epoch: 3, [32000/60000, (53.305%)], loss: 0.089039\n",
      "Train epoch: 3, [33280/60000, (55.437%)], loss: 0.146480\n",
      "Train epoch: 3, [34560/60000, (57.569%)], loss: 0.221821\n",
      "Train epoch: 3, [35840/60000, (59.701%)], loss: 0.360827\n",
      "Train epoch: 3, [37120/60000, (61.834%)], loss: 0.200307\n",
      "Train epoch: 3, [38400/60000, (63.966%)], loss: 0.308794\n",
      "Train epoch: 3, [39680/60000, (66.098%)], loss: 0.120753\n",
      "Train epoch: 3, [40960/60000, (68.230%)], loss: 0.192579\n",
      "Train epoch: 3, [42240/60000, (70.362%)], loss: 0.137677\n",
      "Train epoch: 3, [43520/60000, (72.495%)], loss: 0.119029\n",
      "Train epoch: 3, [44800/60000, (74.627%)], loss: 0.124659\n",
      "Train epoch: 3, [46080/60000, (76.759%)], loss: 0.114221\n",
      "Train epoch: 3, [47360/60000, (78.891%)], loss: 0.295910\n",
      "Train epoch: 3, [48640/60000, (81.023%)], loss: 0.137516\n",
      "Train epoch: 3, [49920/60000, (83.156%)], loss: 0.108318\n",
      "Train epoch: 3, [51200/60000, (85.288%)], loss: 0.119703\n",
      "Train epoch: 3, [52480/60000, (87.420%)], loss: 0.138191\n",
      "Train epoch: 3, [53760/60000, (89.552%)], loss: 0.189830\n",
      "Train epoch: 3, [55040/60000, (91.684%)], loss: 0.234610\n",
      "Train epoch: 3, [56320/60000, (93.817%)], loss: 0.320420\n",
      "Train epoch: 3, [57600/60000, (95.949%)], loss: 0.171063\n",
      "Train epoch: 3, [58880/60000, (98.081%)], loss: 0.138633\n",
      "\n",
      "Test set: Average loss: 0.0009, Accuracy: 9828/10000 (0.983%)\n",
      "Train epoch: 4, [0/60000, (0.000%)], loss: 0.084543\n",
      "Train epoch: 4, [1280/60000, (2.132%)], loss: 0.185988\n",
      "Train epoch: 4, [2560/60000, (4.264%)], loss: 0.205080\n",
      "Train epoch: 4, [3840/60000, (6.397%)], loss: 0.113223\n",
      "Train epoch: 4, [5120/60000, (8.529%)], loss: 0.360352\n",
      "Train epoch: 4, [6400/60000, (10.661%)], loss: 0.278958\n",
      "Train epoch: 4, [7680/60000, (12.793%)], loss: 0.145101\n",
      "Train epoch: 4, [8960/60000, (14.925%)], loss: 0.297722\n",
      "Train epoch: 4, [10240/60000, (17.058%)], loss: 0.116020\n",
      "Train epoch: 4, [11520/60000, (19.190%)], loss: 0.032202\n",
      "Train epoch: 4, [12800/60000, (21.322%)], loss: 0.204407\n",
      "Train epoch: 4, [14080/60000, (23.454%)], loss: 0.068882\n",
      "Train epoch: 4, [15360/60000, (25.586%)], loss: 0.158925\n",
      "Train epoch: 4, [16640/60000, (27.719%)], loss: 0.243091\n",
      "Train epoch: 4, [17920/60000, (29.851%)], loss: 0.132804\n",
      "Train epoch: 4, [19200/60000, (31.983%)], loss: 0.275408\n",
      "Train epoch: 4, [20480/60000, (34.115%)], loss: 0.105654\n",
      "Train epoch: 4, [21760/60000, (36.247%)], loss: 0.064278\n",
      "Train epoch: 4, [23040/60000, (38.380%)], loss: 0.140235\n",
      "Train epoch: 4, [24320/60000, (40.512%)], loss: 0.231076\n",
      "Train epoch: 4, [25600/60000, (42.644%)], loss: 0.098639\n",
      "Train epoch: 4, [26880/60000, (44.776%)], loss: 0.161345\n",
      "Train epoch: 4, [28160/60000, (46.908%)], loss: 0.242947\n",
      "Train epoch: 4, [29440/60000, (49.041%)], loss: 0.232993\n",
      "Train epoch: 4, [30720/60000, (51.173%)], loss: 0.280840\n",
      "Train epoch: 4, [32000/60000, (53.305%)], loss: 0.180498\n",
      "Train epoch: 4, [33280/60000, (55.437%)], loss: 0.098393\n",
      "Train epoch: 4, [34560/60000, (57.569%)], loss: 0.078004\n",
      "Train epoch: 4, [35840/60000, (59.701%)], loss: 0.214483\n",
      "Train epoch: 4, [37120/60000, (61.834%)], loss: 0.077965\n",
      "Train epoch: 4, [38400/60000, (63.966%)], loss: 0.075635\n",
      "Train epoch: 4, [39680/60000, (66.098%)], loss: 0.138995\n",
      "Train epoch: 4, [40960/60000, (68.230%)], loss: 0.225579\n",
      "Train epoch: 4, [42240/60000, (70.362%)], loss: 0.213333\n",
      "Train epoch: 4, [43520/60000, (72.495%)], loss: 0.266284\n",
      "Train epoch: 4, [44800/60000, (74.627%)], loss: 0.330350\n",
      "Train epoch: 4, [46080/60000, (76.759%)], loss: 0.038644\n",
      "Train epoch: 4, [47360/60000, (78.891%)], loss: 0.203715\n",
      "Train epoch: 4, [48640/60000, (81.023%)], loss: 0.104684\n",
      "Train epoch: 4, [49920/60000, (83.156%)], loss: 0.084352\n",
      "Train epoch: 4, [51200/60000, (85.288%)], loss: 0.260788\n",
      "Train epoch: 4, [52480/60000, (87.420%)], loss: 0.366640\n",
      "Train epoch: 4, [53760/60000, (89.552%)], loss: 0.252133\n",
      "Train epoch: 4, [55040/60000, (91.684%)], loss: 0.108655\n",
      "Train epoch: 4, [56320/60000, (93.817%)], loss: 0.133170\n",
      "Train epoch: 4, [57600/60000, (95.949%)], loss: 0.078509\n",
      "Train epoch: 4, [58880/60000, (98.081%)], loss: 0.157990\n",
      "\n",
      "Test set: Average loss: 0.0008, Accuracy: 9847/10000 (0.985%)\n",
      "Train epoch: 5, [0/60000, (0.000%)], loss: 0.163785\n",
      "Train epoch: 5, [1280/60000, (2.132%)], loss: 0.059073\n",
      "Train epoch: 5, [2560/60000, (4.264%)], loss: 0.121604\n",
      "Train epoch: 5, [3840/60000, (6.397%)], loss: 0.082355\n",
      "Train epoch: 5, [5120/60000, (8.529%)], loss: 0.192878\n",
      "Train epoch: 5, [6400/60000, (10.661%)], loss: 0.300460\n",
      "Train epoch: 5, [7680/60000, (12.793%)], loss: 0.206094\n",
      "Train epoch: 5, [8960/60000, (14.925%)], loss: 0.194125\n",
      "Train epoch: 5, [10240/60000, (17.058%)], loss: 0.244244\n",
      "Train epoch: 5, [11520/60000, (19.190%)], loss: 0.150826\n",
      "Train epoch: 5, [12800/60000, (21.322%)], loss: 0.087718\n",
      "Train epoch: 5, [14080/60000, (23.454%)], loss: 0.116468\n",
      "Train epoch: 5, [15360/60000, (25.586%)], loss: 0.107594\n",
      "Train epoch: 5, [16640/60000, (27.719%)], loss: 0.042496\n",
      "Train epoch: 5, [17920/60000, (29.851%)], loss: 0.102984\n",
      "Train epoch: 5, [19200/60000, (31.983%)], loss: 0.145168\n",
      "Train epoch: 5, [20480/60000, (34.115%)], loss: 0.125850\n",
      "Train epoch: 5, [21760/60000, (36.247%)], loss: 0.128107\n",
      "Train epoch: 5, [23040/60000, (38.380%)], loss: 0.090044\n",
      "Train epoch: 5, [24320/60000, (40.512%)], loss: 0.135026\n",
      "Train epoch: 5, [25600/60000, (42.644%)], loss: 0.096490\n",
      "Train epoch: 5, [26880/60000, (44.776%)], loss: 0.088760\n",
      "Train epoch: 5, [28160/60000, (46.908%)], loss: 0.254993\n",
      "Train epoch: 5, [29440/60000, (49.041%)], loss: 0.082568\n",
      "Train epoch: 5, [30720/60000, (51.173%)], loss: 0.309093\n",
      "Train epoch: 5, [32000/60000, (53.305%)], loss: 0.214462\n",
      "Train epoch: 5, [33280/60000, (55.437%)], loss: 0.066798\n",
      "Train epoch: 5, [34560/60000, (57.569%)], loss: 0.159068\n",
      "Train epoch: 5, [35840/60000, (59.701%)], loss: 0.215230\n",
      "Train epoch: 5, [37120/60000, (61.834%)], loss: 0.067879\n",
      "Train epoch: 5, [38400/60000, (63.966%)], loss: 0.183704\n",
      "Train epoch: 5, [39680/60000, (66.098%)], loss: 0.179740\n",
      "Train epoch: 5, [40960/60000, (68.230%)], loss: 0.181703\n",
      "Train epoch: 5, [42240/60000, (70.362%)], loss: 0.101804\n",
      "Train epoch: 5, [43520/60000, (72.495%)], loss: 0.072354\n",
      "Train epoch: 5, [44800/60000, (74.627%)], loss: 0.103330\n",
      "Train epoch: 5, [46080/60000, (76.759%)], loss: 0.138706\n",
      "Train epoch: 5, [47360/60000, (78.891%)], loss: 0.059247\n",
      "Train epoch: 5, [48640/60000, (81.023%)], loss: 0.094805\n",
      "Train epoch: 5, [49920/60000, (83.156%)], loss: 0.181013\n",
      "Train epoch: 5, [51200/60000, (85.288%)], loss: 0.084873\n",
      "Train epoch: 5, [52480/60000, (87.420%)], loss: 0.145092\n",
      "Train epoch: 5, [53760/60000, (89.552%)], loss: 0.210536\n",
      "Train epoch: 5, [55040/60000, (91.684%)], loss: 0.060104\n",
      "Train epoch: 5, [56320/60000, (93.817%)], loss: 0.130811\n",
      "Train epoch: 5, [57600/60000, (95.949%)], loss: 0.068539\n",
      "Train epoch: 5, [58880/60000, (98.081%)], loss: 0.182433\n",
      "\n",
      "Test set: Average loss: 0.0007, Accuracy: 9862/10000 (0.986%)\n",
      "Train epoch: 6, [0/60000, (0.000%)], loss: 0.165222\n",
      "Train epoch: 6, [1280/60000, (2.132%)], loss: 0.231848\n",
      "Train epoch: 6, [2560/60000, (4.264%)], loss: 0.082287\n",
      "Train epoch: 6, [3840/60000, (6.397%)], loss: 0.053097\n",
      "Train epoch: 6, [5120/60000, (8.529%)], loss: 0.286641\n",
      "Train epoch: 6, [6400/60000, (10.661%)], loss: 0.126644\n",
      "Train epoch: 6, [7680/60000, (12.793%)], loss: 0.157656\n",
      "Train epoch: 6, [8960/60000, (14.925%)], loss: 0.094639\n",
      "Train epoch: 6, [10240/60000, (17.058%)], loss: 0.090666\n",
      "Train epoch: 6, [11520/60000, (19.190%)], loss: 0.122798\n",
      "Train epoch: 6, [12800/60000, (21.322%)], loss: 0.336925\n",
      "Train epoch: 6, [14080/60000, (23.454%)], loss: 0.150929\n",
      "Train epoch: 6, [15360/60000, (25.586%)], loss: 0.109693\n",
      "Train epoch: 6, [16640/60000, (27.719%)], loss: 0.044535\n",
      "Train epoch: 6, [17920/60000, (29.851%)], loss: 0.277222\n",
      "Train epoch: 6, [19200/60000, (31.983%)], loss: 0.108413\n",
      "Train epoch: 6, [20480/60000, (34.115%)], loss: 0.152899\n",
      "Train epoch: 6, [21760/60000, (36.247%)], loss: 0.050291\n",
      "Train epoch: 6, [23040/60000, (38.380%)], loss: 0.196497\n",
      "Train epoch: 6, [24320/60000, (40.512%)], loss: 0.127402\n",
      "Train epoch: 6, [25600/60000, (42.644%)], loss: 0.115268\n",
      "Train epoch: 6, [26880/60000, (44.776%)], loss: 0.192206\n",
      "Train epoch: 6, [28160/60000, (46.908%)], loss: 0.168655\n",
      "Train epoch: 6, [29440/60000, (49.041%)], loss: 0.216003\n",
      "Train epoch: 6, [30720/60000, (51.173%)], loss: 0.114575\n",
      "Train epoch: 6, [32000/60000, (53.305%)], loss: 0.118910\n",
      "Train epoch: 6, [33280/60000, (55.437%)], loss: 0.167757\n",
      "Train epoch: 6, [34560/60000, (57.569%)], loss: 0.216222\n",
      "Train epoch: 6, [35840/60000, (59.701%)], loss: 0.036400\n",
      "Train epoch: 6, [37120/60000, (61.834%)], loss: 0.146779\n",
      "Train epoch: 6, [38400/60000, (63.966%)], loss: 0.174631\n",
      "Train epoch: 6, [39680/60000, (66.098%)], loss: 0.112719\n",
      "Train epoch: 6, [40960/60000, (68.230%)], loss: 0.047258\n",
      "Train epoch: 6, [42240/60000, (70.362%)], loss: 0.064939\n",
      "Train epoch: 6, [43520/60000, (72.495%)], loss: 0.139408\n",
      "Train epoch: 6, [44800/60000, (74.627%)], loss: 0.055831\n",
      "Train epoch: 6, [46080/60000, (76.759%)], loss: 0.311884\n",
      "Train epoch: 6, [47360/60000, (78.891%)], loss: 0.180209\n",
      "Train epoch: 6, [48640/60000, (81.023%)], loss: 0.259019\n",
      "Train epoch: 6, [49920/60000, (83.156%)], loss: 0.078839\n",
      "Train epoch: 6, [51200/60000, (85.288%)], loss: 0.149875\n",
      "Train epoch: 6, [52480/60000, (87.420%)], loss: 0.060125\n",
      "Train epoch: 6, [53760/60000, (89.552%)], loss: 0.096434\n",
      "Train epoch: 6, [55040/60000, (91.684%)], loss: 0.334526\n",
      "Train epoch: 6, [56320/60000, (93.817%)], loss: 0.066152\n",
      "Train epoch: 6, [57600/60000, (95.949%)], loss: 0.173239\n",
      "Train epoch: 6, [58880/60000, (98.081%)], loss: 0.190894\n",
      "\n",
      "Test set: Average loss: 0.0007, Accuracy: 9859/10000 (0.986%)\n",
      "Train epoch: 7, [0/60000, (0.000%)], loss: 0.121568\n",
      "Train epoch: 7, [1280/60000, (2.132%)], loss: 0.040193\n",
      "Train epoch: 7, [2560/60000, (4.264%)], loss: 0.116782\n",
      "Train epoch: 7, [3840/60000, (6.397%)], loss: 0.121606\n",
      "Train epoch: 7, [5120/60000, (8.529%)], loss: 0.119143\n",
      "Train epoch: 7, [6400/60000, (10.661%)], loss: 0.066929\n",
      "Train epoch: 7, [7680/60000, (12.793%)], loss: 0.207221\n",
      "Train epoch: 7, [8960/60000, (14.925%)], loss: 0.428897\n",
      "Train epoch: 7, [10240/60000, (17.058%)], loss: 0.040652\n",
      "Train epoch: 7, [11520/60000, (19.190%)], loss: 0.119032\n",
      "Train epoch: 7, [12800/60000, (21.322%)], loss: 0.067924\n",
      "Train epoch: 7, [14080/60000, (23.454%)], loss: 0.087923\n",
      "Train epoch: 7, [15360/60000, (25.586%)], loss: 0.542816\n",
      "Train epoch: 7, [16640/60000, (27.719%)], loss: 0.114976\n",
      "Train epoch: 7, [17920/60000, (29.851%)], loss: 0.106169\n",
      "Train epoch: 7, [19200/60000, (31.983%)], loss: 0.097263\n",
      "Train epoch: 7, [20480/60000, (34.115%)], loss: 0.122753\n",
      "Train epoch: 7, [21760/60000, (36.247%)], loss: 0.119114\n",
      "Train epoch: 7, [23040/60000, (38.380%)], loss: 0.022784\n",
      "Train epoch: 7, [24320/60000, (40.512%)], loss: 0.083190\n",
      "Train epoch: 7, [25600/60000, (42.644%)], loss: 0.110735\n",
      "Train epoch: 7, [26880/60000, (44.776%)], loss: 0.423325\n",
      "Train epoch: 7, [28160/60000, (46.908%)], loss: 0.343882\n",
      "Train epoch: 7, [29440/60000, (49.041%)], loss: 0.081291\n",
      "Train epoch: 7, [30720/60000, (51.173%)], loss: 0.301689\n",
      "Train epoch: 7, [32000/60000, (53.305%)], loss: 0.296781\n",
      "Train epoch: 7, [33280/60000, (55.437%)], loss: 0.022674\n",
      "Train epoch: 7, [34560/60000, (57.569%)], loss: 0.254570\n",
      "Train epoch: 7, [35840/60000, (59.701%)], loss: 0.130723\n",
      "Train epoch: 7, [37120/60000, (61.834%)], loss: 0.151575\n",
      "Train epoch: 7, [38400/60000, (63.966%)], loss: 0.126920\n",
      "Train epoch: 7, [39680/60000, (66.098%)], loss: 0.101649\n",
      "Train epoch: 7, [40960/60000, (68.230%)], loss: 0.052719\n",
      "Train epoch: 7, [42240/60000, (70.362%)], loss: 0.128147\n",
      "Train epoch: 7, [43520/60000, (72.495%)], loss: 0.330305\n",
      "Train epoch: 7, [44800/60000, (74.627%)], loss: 0.069718\n",
      "Train epoch: 7, [46080/60000, (76.759%)], loss: 0.053792\n",
      "Train epoch: 7, [47360/60000, (78.891%)], loss: 0.136248\n",
      "Train epoch: 7, [48640/60000, (81.023%)], loss: 0.446853\n",
      "Train epoch: 7, [49920/60000, (83.156%)], loss: 0.108021\n",
      "Train epoch: 7, [51200/60000, (85.288%)], loss: 0.053190\n",
      "Train epoch: 7, [52480/60000, (87.420%)], loss: 0.057811\n",
      "Train epoch: 7, [53760/60000, (89.552%)], loss: 0.291318\n",
      "Train epoch: 7, [55040/60000, (91.684%)], loss: 0.129851\n",
      "Train epoch: 7, [56320/60000, (93.817%)], loss: 0.158357\n",
      "Train epoch: 7, [57600/60000, (95.949%)], loss: 0.022369\n",
      "Train epoch: 7, [58880/60000, (98.081%)], loss: 0.043080\n",
      "\n",
      "Test set: Average loss: 0.0007, Accuracy: 9866/10000 (0.987%)\n",
      "Train epoch: 8, [0/60000, (0.000%)], loss: 0.065047\n",
      "Train epoch: 8, [1280/60000, (2.132%)], loss: 0.174282\n",
      "Train epoch: 8, [2560/60000, (4.264%)], loss: 0.134286\n",
      "Train epoch: 8, [3840/60000, (6.397%)], loss: 0.333083\n",
      "Train epoch: 8, [5120/60000, (8.529%)], loss: 0.220758\n",
      "Train epoch: 8, [6400/60000, (10.661%)], loss: 0.067451\n",
      "Train epoch: 8, [7680/60000, (12.793%)], loss: 0.154220\n",
      "Train epoch: 8, [8960/60000, (14.925%)], loss: 0.228883\n",
      "Train epoch: 8, [10240/60000, (17.058%)], loss: 0.170701\n",
      "Train epoch: 8, [11520/60000, (19.190%)], loss: 0.221103\n",
      "Train epoch: 8, [12800/60000, (21.322%)], loss: 0.278492\n",
      "Train epoch: 8, [14080/60000, (23.454%)], loss: 0.162379\n",
      "Train epoch: 8, [15360/60000, (25.586%)], loss: 0.165261\n",
      "Train epoch: 8, [16640/60000, (27.719%)], loss: 0.077075\n",
      "Train epoch: 8, [17920/60000, (29.851%)], loss: 0.179298\n",
      "Train epoch: 8, [19200/60000, (31.983%)], loss: 0.348170\n",
      "Train epoch: 8, [20480/60000, (34.115%)], loss: 0.116967\n",
      "Train epoch: 8, [21760/60000, (36.247%)], loss: 0.162650\n",
      "Train epoch: 8, [23040/60000, (38.380%)], loss: 0.053328\n",
      "Train epoch: 8, [24320/60000, (40.512%)], loss: 0.243888\n",
      "Train epoch: 8, [25600/60000, (42.644%)], loss: 0.138938\n",
      "Train epoch: 8, [26880/60000, (44.776%)], loss: 0.228676\n",
      "Train epoch: 8, [28160/60000, (46.908%)], loss: 0.251983\n",
      "Train epoch: 8, [29440/60000, (49.041%)], loss: 0.174612\n",
      "Train epoch: 8, [30720/60000, (51.173%)], loss: 0.081042\n",
      "Train epoch: 8, [32000/60000, (53.305%)], loss: 0.124853\n",
      "Train epoch: 8, [33280/60000, (55.437%)], loss: 0.122414\n",
      "Train epoch: 8, [34560/60000, (57.569%)], loss: 0.125783\n",
      "Train epoch: 8, [35840/60000, (59.701%)], loss: 0.064485\n",
      "Train epoch: 8, [37120/60000, (61.834%)], loss: 0.135360\n",
      "Train epoch: 8, [38400/60000, (63.966%)], loss: 0.050843\n",
      "Train epoch: 8, [39680/60000, (66.098%)], loss: 0.226308\n",
      "Train epoch: 8, [40960/60000, (68.230%)], loss: 0.209170\n",
      "Train epoch: 8, [42240/60000, (70.362%)], loss: 0.148118\n",
      "Train epoch: 8, [43520/60000, (72.495%)], loss: 0.092835\n",
      "Train epoch: 8, [44800/60000, (74.627%)], loss: 0.255687\n",
      "Train epoch: 8, [46080/60000, (76.759%)], loss: 0.099420\n",
      "Train epoch: 8, [47360/60000, (78.891%)], loss: 0.108727\n",
      "Train epoch: 8, [48640/60000, (81.023%)], loss: 0.148893\n",
      "Train epoch: 8, [49920/60000, (83.156%)], loss: 0.140892\n",
      "Train epoch: 8, [51200/60000, (85.288%)], loss: 0.201068\n",
      "Train epoch: 8, [52480/60000, (87.420%)], loss: 0.135683\n",
      "Train epoch: 8, [53760/60000, (89.552%)], loss: 0.122475\n",
      "Train epoch: 8, [55040/60000, (91.684%)], loss: 0.144603\n",
      "Train epoch: 8, [56320/60000, (93.817%)], loss: 0.081020\n",
      "Train epoch: 8, [57600/60000, (95.949%)], loss: 0.123691\n",
      "Train epoch: 8, [58880/60000, (98.081%)], loss: 0.320526\n",
      "\n",
      "Test set: Average loss: 0.0006, Accuracy: 9877/10000 (0.988%)\n",
      "Train epoch: 9, [0/60000, (0.000%)], loss: 0.048149\n",
      "Train epoch: 9, [1280/60000, (2.132%)], loss: 0.163611\n",
      "Train epoch: 9, [2560/60000, (4.264%)], loss: 0.152673\n",
      "Train epoch: 9, [3840/60000, (6.397%)], loss: 0.054129\n",
      "Train epoch: 9, [5120/60000, (8.529%)], loss: 0.151588\n",
      "Train epoch: 9, [6400/60000, (10.661%)], loss: 0.105533\n",
      "Train epoch: 9, [7680/60000, (12.793%)], loss: 0.091766\n",
      "Train epoch: 9, [8960/60000, (14.925%)], loss: 0.053815\n",
      "Train epoch: 9, [10240/60000, (17.058%)], loss: 0.031786\n",
      "Train epoch: 9, [11520/60000, (19.190%)], loss: 0.365128\n",
      "Train epoch: 9, [12800/60000, (21.322%)], loss: 0.077439\n",
      "Train epoch: 9, [14080/60000, (23.454%)], loss: 0.044877\n",
      "Train epoch: 9, [15360/60000, (25.586%)], loss: 0.131460\n",
      "Train epoch: 9, [16640/60000, (27.719%)], loss: 0.043273\n",
      "Train epoch: 9, [17920/60000, (29.851%)], loss: 0.171031\n",
      "Train epoch: 9, [19200/60000, (31.983%)], loss: 0.080126\n",
      "Train epoch: 9, [20480/60000, (34.115%)], loss: 0.021359\n",
      "Train epoch: 9, [21760/60000, (36.247%)], loss: 0.086702\n",
      "Train epoch: 9, [23040/60000, (38.380%)], loss: 0.233533\n",
      "Train epoch: 9, [24320/60000, (40.512%)], loss: 0.277746\n",
      "Train epoch: 9, [25600/60000, (42.644%)], loss: 0.113097\n",
      "Train epoch: 9, [26880/60000, (44.776%)], loss: 0.072117\n",
      "Train epoch: 9, [28160/60000, (46.908%)], loss: 0.138148\n",
      "Train epoch: 9, [29440/60000, (49.041%)], loss: 0.127807\n",
      "Train epoch: 9, [30720/60000, (51.173%)], loss: 0.111889\n",
      "Train epoch: 9, [32000/60000, (53.305%)], loss: 0.181157\n",
      "Train epoch: 9, [33280/60000, (55.437%)], loss: 0.105404\n",
      "Train epoch: 9, [34560/60000, (57.569%)], loss: 0.130666\n",
      "Train epoch: 9, [35840/60000, (59.701%)], loss: 0.106728\n",
      "Train epoch: 9, [37120/60000, (61.834%)], loss: 0.164681\n",
      "Train epoch: 9, [38400/60000, (63.966%)], loss: 0.103807\n",
      "Train epoch: 9, [39680/60000, (66.098%)], loss: 0.247029\n",
      "Train epoch: 9, [40960/60000, (68.230%)], loss: 0.076604\n",
      "Train epoch: 9, [42240/60000, (70.362%)], loss: 0.247547\n",
      "Train epoch: 9, [43520/60000, (72.495%)], loss: 0.076014\n",
      "Train epoch: 9, [44800/60000, (74.627%)], loss: 0.075627\n",
      "Train epoch: 9, [46080/60000, (76.759%)], loss: 0.074105\n",
      "Train epoch: 9, [47360/60000, (78.891%)], loss: 0.114589\n",
      "Train epoch: 9, [48640/60000, (81.023%)], loss: 0.255288\n",
      "Train epoch: 9, [49920/60000, (83.156%)], loss: 0.084833\n",
      "Train epoch: 9, [51200/60000, (85.288%)], loss: 0.280927\n",
      "Train epoch: 9, [52480/60000, (87.420%)], loss: 0.109074\n",
      "Train epoch: 9, [53760/60000, (89.552%)], loss: 0.090260\n",
      "Train epoch: 9, [55040/60000, (91.684%)], loss: 0.198043\n",
      "Train epoch: 9, [56320/60000, (93.817%)], loss: 0.059121\n",
      "Train epoch: 9, [57600/60000, (95.949%)], loss: 0.038994\n",
      "Train epoch: 9, [58880/60000, (98.081%)], loss: 0.162592\n",
      "\n",
      "Test set: Average loss: 0.0006, Accuracy: 9882/10000 (0.988%)\n",
      "Train epoch: 10, [0/60000, (0.000%)], loss: 0.242288\n",
      "Train epoch: 10, [1280/60000, (2.132%)], loss: 0.166610\n",
      "Train epoch: 10, [2560/60000, (4.264%)], loss: 0.056304\n",
      "Train epoch: 10, [3840/60000, (6.397%)], loss: 0.116800\n",
      "Train epoch: 10, [5120/60000, (8.529%)], loss: 0.055133\n",
      "Train epoch: 10, [6400/60000, (10.661%)], loss: 0.189788\n",
      "Train epoch: 10, [7680/60000, (12.793%)], loss: 0.058882\n",
      "Train epoch: 10, [8960/60000, (14.925%)], loss: 0.259214\n",
      "Train epoch: 10, [10240/60000, (17.058%)], loss: 0.074921\n",
      "Train epoch: 10, [11520/60000, (19.190%)], loss: 0.043468\n",
      "Train epoch: 10, [12800/60000, (21.322%)], loss: 0.161546\n",
      "Train epoch: 10, [14080/60000, (23.454%)], loss: 0.136446\n",
      "Train epoch: 10, [15360/60000, (25.586%)], loss: 0.133540\n",
      "Train epoch: 10, [16640/60000, (27.719%)], loss: 0.043206\n",
      "Train epoch: 10, [17920/60000, (29.851%)], loss: 0.270406\n",
      "Train epoch: 10, [19200/60000, (31.983%)], loss: 0.088739\n",
      "Train epoch: 10, [20480/60000, (34.115%)], loss: 0.055173\n",
      "Train epoch: 10, [21760/60000, (36.247%)], loss: 0.208465\n",
      "Train epoch: 10, [23040/60000, (38.380%)], loss: 0.115651\n",
      "Train epoch: 10, [24320/60000, (40.512%)], loss: 0.099958\n",
      "Train epoch: 10, [25600/60000, (42.644%)], loss: 0.102475\n",
      "Train epoch: 10, [26880/60000, (44.776%)], loss: 0.041343\n",
      "Train epoch: 10, [28160/60000, (46.908%)], loss: 0.087422\n",
      "Train epoch: 10, [29440/60000, (49.041%)], loss: 0.083689\n",
      "Train epoch: 10, [30720/60000, (51.173%)], loss: 0.060303\n",
      "Train epoch: 10, [32000/60000, (53.305%)], loss: 0.135098\n",
      "Train epoch: 10, [33280/60000, (55.437%)], loss: 0.421596\n",
      "Train epoch: 10, [34560/60000, (57.569%)], loss: 0.100496\n",
      "Train epoch: 10, [35840/60000, (59.701%)], loss: 0.060110\n",
      "Train epoch: 10, [37120/60000, (61.834%)], loss: 0.169034\n",
      "Train epoch: 10, [38400/60000, (63.966%)], loss: 0.073057\n",
      "Train epoch: 10, [39680/60000, (66.098%)], loss: 0.254019\n",
      "Train epoch: 10, [40960/60000, (68.230%)], loss: 0.179300\n",
      "Train epoch: 10, [42240/60000, (70.362%)], loss: 0.280230\n",
      "Train epoch: 10, [43520/60000, (72.495%)], loss: 0.044075\n",
      "Train epoch: 10, [44800/60000, (74.627%)], loss: 0.221028\n",
      "Train epoch: 10, [46080/60000, (76.759%)], loss: 0.085696\n",
      "Train epoch: 10, [47360/60000, (78.891%)], loss: 0.180238\n",
      "Train epoch: 10, [48640/60000, (81.023%)], loss: 0.136802\n",
      "Train epoch: 10, [49920/60000, (83.156%)], loss: 0.083049\n",
      "Train epoch: 10, [51200/60000, (85.288%)], loss: 0.074689\n",
      "Train epoch: 10, [52480/60000, (87.420%)], loss: 0.099783\n",
      "Train epoch: 10, [53760/60000, (89.552%)], loss: 0.137223\n",
      "Train epoch: 10, [55040/60000, (91.684%)], loss: 0.217546\n",
      "Train epoch: 10, [56320/60000, (93.817%)], loss: 0.105939\n",
      "Train epoch: 10, [57600/60000, (95.949%)], loss: 0.198390\n",
      "Train epoch: 10, [58880/60000, (98.081%)], loss: 0.086013\n",
      "\n",
      "Test set: Average loss: 0.0006, Accuracy: 9881/10000 (0.988%)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, n_epochs+1):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3a877550-8ba1-49d5-910e-731afb6a9e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './model.pth')\n",
    "torch.save(optimizer.state_dict(), './optimizer.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
